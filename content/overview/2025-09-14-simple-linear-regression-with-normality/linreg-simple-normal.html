---
title: Simple linear regression (with normality)
date: '2025-09-14'
slug: simple-linear-regression-with-normality
categories:
  - General
---



<p>We make one additional assumption to the <a href="/overview/2025-05-16-linreg-simple/linreg-simple/">simple linear regression assumptions</a>, which is that the error variable <span class="math inline">\(\varepsilon_i\)</span> is <em>normally distributed</em>. Its center is still 0, and its variance is still <span class="math inline">\(\sigma^2\)</span>. It remains independent and identically distributed across levels of <span class="math inline">\(X\)</span>.</p>
<p>As a result, <span class="math inline">\(Y_i\)</span> is also normally distributed with <span class="math inline">\(E(Y_i) = \beta_0 + \beta_1X_i, V(Y_i) = \sigma^2\)</span>.</p>
<p>You might ask why this is justified. Consider that <span class="math inline">\(\varepsilon\)</span> includes any other variables other than <span class="math inline">\(X\)</span>, how randomness affects these other variables, and potential measurement errors. Like most things in the world, the effect of these factors in aggregate <em>are</em> likely to follow a normal distribution.</p>
<div id="adding-the-assumption-of-normality" class="section level2">
<h2>Adding the assumption of normality</h2>
<p><span class="math display">\[ \varepsilon_i \sim N(0, \sigma^2) \implies (\beta_0 + \beta_1X_i + \varepsilon_i)\sim N(\beta_0+\beta_1X_i+0, \sigma^2)\implies Y_i =Y|X_i \sim(\beta_0 + \beta_1 X_i, \sigma^2) \]</span>
<span class="math inline">\(Y_i\)</span> or <span class="math inline">\(Y|X_i\)</span> is normally distributed about a line describing a
linear relationship. Its variance is the same across
<span class="math inline">\(X_i\)</span>’s.</p>
<div id="linear-regression-model" class="section level3">
<h3>Linear regression model</h3>
<p>The resulting model is:</p>
<p><span class="math display">\[ Y|X = \beta_0 + \beta_1X + \varepsilon, \varepsilon \sim  N(0, \sigma^2) \implies Y|X \sim N(\beta_0+\beta_1X, \sigma^2) \]</span>
Which puts us in the perfect position to conduct inference on <span class="math inline">\(Y_i\)</span>’s. I
mean, look at the picture below. There exists a distribution for every
single point!</p>
</div>
</div>
<div id="testing-our-model" class="section level1">
<h1>Testing our model</h1>
<p><a href="/inference_tests/2025-06-17-t-test-linreg/t-test-linreg">See here.</a></p>
</div>
<div id="caveats" class="section level1">
<h1>Caveats</h1>
<p><strong>Again, note that normality of residuals is not required for the OLS method, but IS required for inference using the linear model. (Kutner p.26) </strong></p>
<p>Linear regressions can be misapplied in the case of:
- Nonlinear relationships
- Making inferences about <span class="math inline">\(Y|X_i\)</span> when <span class="math inline">\(X_i\)</span> is beyond the
range of the sample <span class="math inline">\(X\)</span> used to fit the model</p>
</div>
