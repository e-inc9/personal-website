<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Inference_tests on A minimal Hugo website</title>
    <link>http://localhost:4321/inference_tests/</link>
    <description>Recent content in Inference_tests on A minimal Hugo website</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Oct 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:4321/inference_tests/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Lack of fit (F-test)</title>
      <link>http://localhost:4321/inference_tests/2025-10-10-lack-of-fit-f-test/lof/</link>
      <pubDate>Fri, 10 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/inference_tests/2025-10-10-lack-of-fit-f-test/lof/</guid>
      <description>&lt;p&gt;We introduce a test to determine whether a given regression (not necessarily linear) adequately fits the data.&lt;/p&gt;&#xA;&lt;div id=&#34;assumptions&#34; class=&#34;section level3&#34;&gt;&#xA;&lt;h3&gt;Assumptions&lt;/h3&gt;&#xA;&lt;ol style=&#34;list-style-type: decimal&#34;&gt;&#xA;&lt;li&gt;Observations &lt;span class=&#34;math inline&#34;&gt;\((X,Y)\)&lt;/span&gt; are independent, normally distributed, and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; has the same variance &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;&lt;/li&gt;&#xA;&lt;li&gt;Data have repeat observations (replicates) at one or more &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; levels (replications).&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;This test involves two models. The first is a “full” model, which we compare against, and a “reduced” model, which is a given regression model. The goal is to compare the _______ of the reduced model vs. the full model through a ratio, which follows an &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt; distribution.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Constancy of variance</title>
      <link>http://localhost:4321/inference_tests/2025-10-06-constancy-of-variance/const_var/</link>
      <pubDate>Mon, 06 Oct 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/inference_tests/2025-10-06-constancy-of-variance/const_var/</guid>
      <description>&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;Given a sample from a population, we’d often like to know whether that sample comes from a normally distributed population. We present two tests. The Brown-Forsythe test, and the Breusch-Pagan test. The former makes no assumptions about the population, the latter does make assumptions about the population.&lt;/p&gt;&#xA;&lt;div id=&#34;brown-forsythe&#34; class=&#34;section level2&#34;&gt;&#xA;&lt;h2&gt;Brown-Forsythe&lt;/h2&gt;&#xA;&lt;p&gt;Say we’d like to see if &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; has a constant variance in the population. Based on sampled &lt;span class=&#34;math inline&#34;&gt;\(y_1... y_n\)&lt;/span&gt;,&lt;/p&gt;&#xA;&lt;p&gt;We&#xA;1) divide the data into two groups consisting of &lt;span class=&#34;math inline&#34;&gt;\(y_{1i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y_{2i}\)&lt;/span&gt;&#xA;2) within each group, calculate &lt;span class=&#34;math inline&#34;&gt;\(d_{1i}=|y_{1i} - median(y_1)|\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(d_{2i} = |y_{2i} - median(y_2)|\)&lt;/span&gt;&#xA;3) calculate the sample means of said absolute departures from each group&#xA;4) The test statistic:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Confidence intervals</title>
      <link>http://localhost:4321/inference_tests/2025-09-29-confidence-intervals/confidence-intervals/</link>
      <pubDate>Mon, 29 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/inference_tests/2025-09-29-confidence-intervals/confidence-intervals/</guid>
      <description>&lt;p&gt;We begin with some obvious truths: for a given estimate &lt;code&gt;\(\hat \theta\)&lt;/code&gt; of parameter &lt;code&gt;\(\theta\)&lt;/code&gt; &amp;ndash; say &lt;code&gt;\(\bar x\)&lt;/code&gt; of &lt;code&gt;\(\mu\)&lt;/code&gt; &amp;ndash; &lt;code&gt;\(\hat \theta\)&lt;/code&gt; is virtually never &lt;code&gt;\(\theta\)&lt;/code&gt;. Furthermore, the distance of &lt;code&gt;\(\hat \theta\)&lt;/code&gt; from &lt;code&gt;\(\theta\)&lt;/code&gt; is virtually unknown. If we&amp;rsquo;re interested in &lt;code&gt;\(\theta\)&lt;/code&gt;, &lt;code&gt;\(\hat \theta\)&lt;/code&gt; is of little use on its own.&lt;/p&gt;&#xA;&lt;p&gt;We can, however, use properties of the distribution of &lt;code&gt;\(\hat \theta\)&lt;/code&gt; (which are downstream of our sample) to come up with a range, or  &lt;em&gt;interval&lt;/em&gt;, of plausible &lt;code&gt;\(\theta\)&lt;/code&gt;&amp;rsquo;s. This, surely, is more sensible than blindly trusting &lt;code&gt;\(\hat \theta\)&lt;/code&gt; as &lt;code&gt;\(\theta\)&lt;/code&gt; (or anywhere close to it).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Correlation</title>
      <link>http://localhost:4321/inference_tests/2025-09-28-t-test-correlation/t-test-corr/</link>
      <pubDate>Sun, 28 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/inference_tests/2025-09-28-t-test-correlation/t-test-corr/</guid>
      <description>&lt;h2 id=&#34;correlation&#34;&gt;Correlation&lt;/h2&gt;&#xA;&lt;p&gt;We consider the definition of population correlation between variables &lt;code&gt;\(X,Y\)&lt;/code&gt;&lt;/p&gt;&#xA;$$&#xA;\rho_{XY} = \frac{Cov(X,Y)}{\sigma_X \sigma_Y}&#xA;$$&lt;h2 id=&#34;estimator&#34;&gt;Estimator&lt;/h2&gt;&#xA;&lt;p&gt;The Pearson product-moment correlation coefficient &amp;ndash; &lt;code&gt;\(r_{XY}\)&lt;/code&gt; &amp;ndash; is an estimator for &lt;code&gt;\(\rho_{XY}\)&lt;/code&gt;. It is biased, but the bias is small when &lt;code&gt;\(n\)&lt;/code&gt; is large. Like &lt;code&gt;\(\rho\)&lt;/code&gt;, it has range &lt;code&gt;\([-1, 1]\)&lt;/code&gt; and the interpretation is the same.&lt;/p&gt;&#xA;$$&#xA;r_{XY} = \frac{ \sum(X_i - \bar X)(Y_i - \bar Y)}{\sqrt{\sum(X_i - \bar X)^2}\sqrt{\sum(Y_i - \bar Y)^2} }&#xA;$$&lt;h2 id=&#34;inference&#34;&gt;Inference&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;When &lt;code&gt;\(X,Y\)&lt;/code&gt; are bivariate normally distributed&lt;/strong&gt; (and with appropriately large n), an appropriate test statistic is&lt;/p&gt;</description>
    </item>
    <item>
      <title>F-test (ANOVA/linear regressions)</title>
      <link>http://localhost:4321/inference_tests/2025-09-24-f-test-anova-linear-regressions/f-test/</link>
      <pubDate>Wed, 24 Sep 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/inference_tests/2025-09-24-f-test-anova-linear-regressions/f-test/</guid>
      <description>&lt;p&gt;In the &lt;a href=&#34;http://localhost:4321/distrib/2025-09-23-simple-linear-regression-anova-cut/linreg-anova/&#34;&gt;ANOVA cut of linear regression&lt;/a&gt;, we ended on &lt;code&gt;\(MSR\)&lt;/code&gt; and &lt;code&gt;\(MSE\)&lt;/code&gt;, which are two measures of variance. &lt;code&gt;\(MSR\)&lt;/code&gt; measures the variance explained by a fitted line, while &lt;code&gt;\(MSE\)&lt;/code&gt; measures the variance of observations about that (in spite of) the fitted line.&lt;/p&gt;&#xA;&lt;p&gt;Given that they are both random variables with centers:&#xA;&lt;/p&gt;&#xA;$$&#xA;E(MSE)= \sigma^2\\&#xA;E(MSR) = \sigma^2 + \beta_1 ^2 \sum(X_i - \bar X)^2&#xA;$$&lt;p&gt;&#xA;We conclude that the distribution of &lt;code&gt;\(MSR\)&lt;/code&gt; is &lt;em&gt;to the right of&lt;/em&gt; the distribution of &lt;code&gt;\(MSE\)&lt;/code&gt; if &lt;code&gt;\(\beta_1 \ne 0\)&lt;/code&gt;, and thus computed &lt;code&gt;\(MSR\)&lt;/code&gt; is likely to be greater than &lt;code&gt;\(MSE\)&lt;/code&gt;. If &lt;code&gt;\(\beta_1 = 0\)&lt;/code&gt;, then &lt;code&gt;\(MSR\)&lt;/code&gt; is likely to equal &lt;code&gt;\(MSE\)&lt;/code&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>T-test (linear regressions)</title>
      <link>http://localhost:4321/inference_tests/2025-06-17-t-test-linreg/t-test-linreg/</link>
      <pubDate>Tue, 17 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/inference_tests/2025-06-17-t-test-linreg/t-test-linreg/</guid>
      <description>&lt;p&gt;Just as the estimators sample mean and sample variance follow a distribution, so do the estimators  &lt;code&gt;\(\hat \beta_0, \hat \beta_1\)&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Even though it can be argued that there does not exist a &amp;ldquo;true&amp;rdquo; &lt;code&gt;\(\beta_0\)&lt;/code&gt; and &lt;code&gt;\(\beta_1\)&lt;/code&gt; in the same way a true &lt;code&gt;\(\mu, \sigma\)&lt;/code&gt; might (the former comes from an assumption-laden construct that we use to interpret reality while the other objectively exists in reality), we could say that having identified phenomena for which a linear regression is applicable, there  &lt;em&gt;does&lt;/em&gt; exist a regression line that exists for all existing &amp;ldquo;population&amp;rdquo; data on this phenomena. We&amp;rsquo;d like to infer this &lt;code&gt;\(\beta_0, \beta_1\)&lt;/code&gt; that&amp;rsquo;s &amp;ldquo;out there&amp;rdquo;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>T-test (population mean)</title>
      <link>http://localhost:4321/inference_tests/2025-06-13-t-test/t-test/</link>
      <pubDate>Fri, 13 Jun 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/inference_tests/2025-06-13-t-test/t-test/</guid>
      <description>&lt;script src=&#34;http://localhost:4321/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;&#xA;&lt;link href=&#34;http://localhost:4321/rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;&#xA;&lt;script src=&#34;http://localhost:4321/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;&#xA;&lt;link href=&#34;http://localhost:4321/rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;&#xA;&lt;p&gt;The t-test can be used to make inferences regarding a population mean when we have a sample from said population.&lt;/p&gt;&#xA;&lt;p&gt;The assumptions are that&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;The sample mean follows an approximately normal distribution. This requires either &lt;code&gt;\(n \ge 30\)&lt;/code&gt; or the population to be normally distributed, either of which are ensures &lt;code&gt;\(\bar X \sim N\)&lt;/code&gt; (approximately).&lt;/li&gt;&#xA;&lt;li&gt;The numerator and denominator are independent, which can be assumed for a sample drawn from a normal population.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;The statistic used is&lt;/p&gt;</description>
    </item>
    <item>
      <title>ANOVA (in progress)</title>
      <link>http://localhost:4321/inference_tests/anova/</link>
      <pubDate>Sat, 26 Apr 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/inference_tests/anova/</guid>
      <description>&lt;h1 id=&#34;intro&#34;&gt;Intro&lt;/h1&gt;&#xA;&lt;p&gt;ANOVA stands for analysis of variance. The goal of ANOVA is, for a variable measured on more than one group of data, to &lt;strong&gt;use the variance of our measurements&lt;/strong&gt; to determine whether the population mean of those groups is different between at least one pair of groups.&lt;/p&gt;&#xA;\[ H_0: \mu_1 = \mu_2 = ... =\mu_n \]&lt;p&gt;&#xA;&lt;/p&gt;&#xA;\[ H_a: \mu_i \ne \mu_j \text{ for } i \ne j \]&lt;p&gt;You might wonder why we are analyzing &lt;em&gt;variance&lt;/em&gt; to get at a truth involving means &amp;ndash; I certainly did. The best way to intuit &lt;em&gt;why&lt;/em&gt; is through a simple exercise.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
